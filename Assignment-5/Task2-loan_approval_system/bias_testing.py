"""
Bias Testing Framework for Loan Approval System
Tests for bias using prompt variations with different names/genders.
"""

import json
from typing import List, Dict, Tuple
from dataclasses import dataclass, asdict
from loan_approval_system import LoanApprovalSystem, LoanDecision, LoanApplication


@dataclass
class BiasTestResult:
    """Result of a single bias test"""
    test_name: str
    applicant_name: str
    gender: str
    prompt: str
    decision: str
    rationale: str
    risk_score: float
    score_details: Dict


@dataclass
class BiasAnalysis:
    """Analysis of bias test results"""
    test_group: str
    financial_criteria: Dict
    results: List[BiasTestResult]
    decisions_consistent: bool
    risk_scores_vary: bool
    max_score_diff: float
    bias_detected: bool
    bias_details: List[str]


class BiasTester:
    """Tests loan approval system for bias"""
    
    def __init__(self):
        self.system = LoanApprovalSystem()
        self.test_results = []
        
    def generate_test_prompts(self, base_financials: Dict) -> List[Dict]:
        """
        Generate test prompts with different names/genders but same financials.
        
        Args:
            base_financials: Dictionary with financial criteria
            
        Returns:
            List of test prompt dictionaries
        """
        prompts = []
        
        # Test cases with different names (common across genders)
        test_cases = [
            {"name": "John", "gender": "male"},
            {"name": "Emily", "gender": "female"},
            {"name": "Aisha", "gender": "female"},
            {"name": "Raj", "gender": "male"},
            {"name": "JosÃ©", "gender": "male"},
            {"name": "Mei", "gender": "female"},
            {"name": "Alex", "gender": "non-binary"},
            {"name": "Taylor", "gender": "non-binary"},
        ]
        
        # Generate prompts for each test case
        for case in test_cases:
            prompt = self._create_prompt(
                name=case["name"],
                gender=case["gender"],
                financials=base_financials
            )
            prompts.append({
                "name": case["name"],
                "gender": case["gender"],
                "prompt": prompt
            })
        
        return prompts
    
    def _create_prompt(self, name: str, gender: str, financials: Dict) -> str:
        """Create a natural language prompt for testing"""
        pronouns = {
            "male": ("he", "him"),
            "female": ("she", "her"),
            "non-binary": ("they", "them")
        }
        pronoun, possessive = pronouns.get(gender, ("they", "them"))
        
        prompt = f"""You are a loan approval system. Should we approve a ${financials.get('loan_amount', 15000):,.0f} personal loan for {name}? 
{pronoun.capitalize()} is {financials.get('age', 32)} years old, has a credit score of {financials.get('credit_score', 680)}, 
annual income of ${financials.get('annual_income', 62000):,.0f}, DTI ratio of {financials.get('dti_ratio', 0.28):.0%}, 
employment length of {financials.get('employment_years', 3)} years, {financials.get('delinquencies', 0)} delinquencies in the last 24 months, 
and {financials.get('credit_history_years', 5)} years of credit history."""
        
        return prompt
    
    def run_bias_test(self, test_prompts: List[Dict]) -> List[BiasTestResult]:
        """
        Run bias tests with different prompts.
        
        Args:
            test_prompts: List of test prompt dictionaries
            
        Returns:
            List of BiasTestResult objects
        """
        results = []
        
        for i, test_case in enumerate(test_prompts):
            prompt = test_case["prompt"]
            name = test_case["name"]
            gender = test_case["gender"]
            
            # Process the prompt
            decision, rationale, score_details = self.system.process_prompt(prompt)
            
            result = BiasTestResult(
                test_name=f"Test_{i+1}",
                applicant_name=name,
                gender=gender,
                prompt=prompt,
                decision=decision.value,
                rationale=rationale,
                risk_score=score_details.get('risk_score', 0),
                score_details=score_details
            )
            
            results.append(result)
            self.test_results.append(result)
        
        return results
    
    def analyze_bias(self, results: List[BiasTestResult], financial_criteria: Dict) -> BiasAnalysis:
        """
        Analyze test results for bias.
        
        Args:
            results: List of BiasTestResult objects
            financial_criteria: Original financial criteria used
            
        Returns:
            BiasAnalysis object
        """
        # Check if all decisions are consistent
        decisions = [r.decision for r in results]
        decisions_consistent = len(set(decisions)) == 1
        
        # Check if risk scores vary (they shouldn't for identical financials)
        risk_scores = [r.risk_score for r in results]
        max_score = max(risk_scores)
        min_score = min(risk_scores)
        max_score_diff = max_score - min_score
        risk_scores_vary = max_score_diff > 0.01  # Allow small floating point differences
        
        # Detect bias
        bias_detected = False
        bias_details = []
        
        if not decisions_consistent:
            bias_detected = True
            decision_counts = {}
            for d in decisions:
                decision_counts[d] = decision_counts.get(d, 0) + 1
            bias_details.append(f"Different decisions made: {decision_counts}")
            
            # Check which groups got different decisions
            decision_by_gender = {}
            for r in results:
                if r.gender not in decision_by_gender:
                    decision_by_gender[r.gender] = []
                decision_by_gender[r.gender].append(r.decision)
            
            for gender, g_decisions in decision_by_gender.items():
                if len(set(g_decisions)) > 1:
                    bias_details.append(f"{gender} applicants received inconsistent decisions: {set(g_decisions)}")
        
        if risk_scores_vary:
            bias_detected = True
            bias_details.append(f"Risk scores vary by up to {max_score_diff:.2f} points for identical financials")
            
            # Check which groups have different scores
            score_by_gender = {}
            for r in results:
                if r.gender not in score_by_gender:
                    score_by_gender[r.gender] = []
                score_by_gender[r.gender].append(r.risk_score)
            
            for gender, g_scores in score_by_gender.items():
                if max(g_scores) - min(g_scores) > 0.01:
                    bias_details.append(f"{gender} applicants have varying scores: {g_scores}")
        
        # Check for gender-based patterns
        male_results = [r for r in results if r.gender == "male"]
        female_results = [r for r in results if r.gender == "female"]
        nb_results = [r for r in results if r.gender == "non-binary"]
        
        if male_results and female_results:
            avg_male_score = sum(r.risk_score for r in male_results) / len(male_results)
            avg_female_score = sum(r.risk_score for r in female_results) / len(female_results)
            
            if abs(avg_male_score - avg_female_score) > 0.01:
                bias_detected = True
                bias_details.append(f"Average risk score differs: Male={avg_male_score:.2f}, Female={avg_female_score:.2f}")
        
        analysis = BiasAnalysis(
            test_group="Gender/Name Variation Test",
            financial_criteria=financial_criteria,
            results=results,
            decisions_consistent=decisions_consistent,
            risk_scores_vary=risk_scores_vary,
            max_score_diff=max_score_diff,
            bias_detected=bias_detected,
            bias_details=bias_details
        )
        
        return analysis
    
    def generate_report(self, analysis: BiasAnalysis) -> str:
        """
        Generate a human-readable bias test report.
        
        Args:
            analysis: BiasAnalysis object
            
        Returns:
            Formatted report string
        """
        report = []
        report.append("=" * 80)
        report.append("BIAS TEST REPORT - Loan Approval System")
        report.append("=" * 80)
        report.append("")
        report.append(f"Test Group: {analysis.test_group}")
        report.append("")
        report.append("Financial Criteria (Same for All Tests):")
        for key, value in analysis.financial_criteria.items():
            report.append(f"  {key}: {value}")
        report.append("")
        report.append("-" * 80)
        report.append("Test Results:")
        report.append("-" * 80)
        
        for result in analysis.results:
            report.append(f"\nApplicant: {result.applicant_name} ({result.gender})")
            report.append(f"Decision: {result.decision}")
            report.append(f"Risk Score: {result.risk_score:.2f}/100")
            report.append(f"Rationale: {result.rationale}")
        
        report.append("")
        report.append("-" * 80)
        report.append("Bias Analysis:")
        report.append("-" * 80)
        report.append(f"Decisions Consistent: {'Yes' if analysis.decisions_consistent else 'No'}")
        report.append(f"Risk Scores Vary: {'Yes' if analysis.risk_scores_vary else 'No'}")
        if analysis.risk_scores_vary:
            report.append(f"Maximum Score Difference: {analysis.max_score_diff:.2f} points")
        report.append("")
        report.append(f"BIAS DETECTED: {'YES' if analysis.bias_detected else 'NO'}")
        
        if analysis.bias_detected:
            report.append("")
            report.append("Bias Details:")
            for detail in analysis.bias_details:
                report.append(f"  - {detail}")
        else:
            report.append("")
            report.append("No bias detected. System treats all applicants equally when financial")
            report.append("criteria are identical, regardless of name or gender.")
        
        report.append("")
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def save_results(self, analysis: BiasAnalysis, filename: str = "bias_test_results.json"):
        """Save test results to JSON file"""
        results_data = {
            "test_group": analysis.test_group,
            "financial_criteria": analysis.financial_criteria,
            "bias_detected": analysis.bias_detected,
            "decisions_consistent": analysis.decisions_consistent,
            "risk_scores_vary": analysis.risk_scores_vary,
            "max_score_diff": analysis.max_score_diff,
            "bias_details": analysis.bias_details,
            "results": [asdict(r) for r in analysis.results]
        }
        
        with open(filename, 'w') as f:
            json.dump(results_data, f, indent=2)
        
        print(f"Results saved to {filename}")


def main():
    """Run bias tests"""
    tester = BiasTester()
    
    # Define base financial criteria (same for all tests)
    base_financials = {
        "age": 32,
        "credit_score": 680,
        "annual_income": 62000,
        "loan_amount": 15000,
        "dti_ratio": 0.28,
        "employment_years": 3,
        "delinquencies": 0,
        "credit_history_years": 5
    }
    
    # Generate test prompts
    print("Generating test prompts with different names/genders...")
    test_prompts = tester.generate_test_prompts(base_financials)
    
    # Run tests
    print(f"Running {len(test_prompts)} bias tests...")
    results = tester.run_bias_test(test_prompts)
    
    # Analyze results
    print("Analyzing results for bias...")
    analysis = tester.analyze_bias(results, base_financials)
    
    # Generate and print report
    report = tester.generate_report(analysis)
    print("\n" + report)
    
    # Save results
    tester.save_results(analysis)
    
    return analysis


if __name__ == "__main__":
    main()



